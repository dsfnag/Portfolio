{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Формирование учебного датасета к проекту SkiilFactory\n",
    "## «Кто хочет стать миллионером кинопроката?»\n",
    "### На основе открытых данных IMDb\n",
    "\n",
    "В старом учебном датасете к проекту всего 1889 фильмов. Из-за этого с датасетом работать скучновато.\\\n",
    "А что, если увеличить размер датасета на пару порядков? Стало бы гораздо интереснее.\n",
    "\n",
    "Надо всего лишь загрузить данные с официального сайта IMDb и перевести датасет в нужный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io, os, gzip, shutil\n",
    "\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Официальное расположение датасетов IMDB\n",
    "PATH_IMDB_DATASETS = 'https://datasets.imdbws.com/'\n",
    "DATASET_MOVIES = 'title.basics.tsv.gz' # фильмы\n",
    "DATASET_RATINGS = 'title.ratings.tsv.gz' # оценки\n",
    "DATASET_CASTS = 'title.principals.tsv.gz' # сведения о съемочных группах, в т.ч. id актеров и режиссеров\n",
    "DATASET_PEOPLES = 'name.basics.tsv.gz' # информация о людях по их id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![IMDB logo](https://m.media-amazon.com/images/G/01/IMDb/BG_rectangle._CB1509060989_SY230_SX307_AL_.png)\n",
    "# [IMDb Datasets](https://www.imdb.com/interfaces/)\n",
    "Subsets of IMDb data are available for access to customers for personal and non-commercial use. You can hold local copies of this data, and it is subject to our terms and conditions. Please refer to the Non-Commercial Licensing and copyright/license and verify compliance.\n",
    "\n",
    "## Data Location\n",
    "\n",
    "The dataset files can be accessed and downloaded from https://datasets.imdbws.com/. The data is refreshed daily. ***(НЕТ, увы...)***\n",
    "\n",
    "## IMDb Dataset Details\n",
    "\n",
    "Each dataset is contained in a gzipped, tab-separated-values (TSV) formatted file in the UTF-8 character set. The first line in each file contains headers that describe what is in each column. A ‘`\\N`’ is used to denote that a particular field is missing or null for that title/name. The available datasets are as follows:\n",
    "\n",
    "### title.basics.tsv.gz - Contains the following information for titles:\n",
    "- `tconst` (string) - alphanumeric unique identifier of the title\n",
    "- `titleType` (string) – the type/format of the title (e.g. movie, short, tvseries, tvepisode, video, etc)\n",
    "- `primaryTitle` (string) – the more popular title / the title used by the filmmakers on promotional materials at the point of release\n",
    "- `originalTitle` (string) - original title, in the original language\n",
    "- `isAdult` (boolean) - 0: non-adult title; 1: adult title\n",
    "- `startYear` (YYYY) – represents the release year of a title. In the case of TV Series, it is the series start year\n",
    "- `endYear` (YYYY) – TV Series end year. ‘`\\N`’ for all other title types\n",
    "- `runtimeMinutes` – primary runtime of the title, in minutes\n",
    "- `genres` (string array) – includes up to three genres associated with the title\n",
    "### title.ratings.tsv.gz – Contains the IMDb rating and votes information for titles\n",
    "- `tconst` (string) - alphanumeric unique identifier of the title\n",
    "- `averageRating` – weighted average of all the individual user ratings\n",
    "- `numVotes` - number of votes the title has received\n",
    "### title.principals.tsv.gz – Contains the principal cast/crew for titles\n",
    "- `tconst` (string) - alphanumeric unique identifier of the title\n",
    "- `ordering` (integer) – a number to uniquely identify rows for a given titleId\n",
    "- `nconst` (string) - alphanumeric unique identifier of the name/person\n",
    "- `category` (string) - the category of job that person was in\n",
    "- `job (string)` - the specific job title if applicable, else ‘`\\N`’\n",
    "- `characters` (string) - the name of the character played if applicable, else ‘`\\N`’\n",
    "### name.basics.tsv.gz – Contains the following information for names:\n",
    "- `nconst` (string) - alphanumeric unique identifier of the name/person\n",
    "- `primaryName` (string)– name by which the person is most often credited\n",
    "- `birthYear` – in YYYY format\n",
    "- `deathYear` – in YYYY format if applicable, else ‘`\\N`’\n",
    "- `primaryProfession` (array of strings)– the top-3 professions of the person\n",
    "- `knownForTitles` (array of tconsts) – titles the person is known for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не будем скачивать новую базу, если датасеты лежат в подпапке /datasets. Создадим папку, если ее нет\n",
    "# Для обновления датасетов надо просто удалить файлы из этой папки или папку целиком\n",
    "os.makedirs('datasets', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка любого датасета IMDB производится одним и тем же способом\n",
    "# Поэтому создадим функцию для загрузки датасета\n",
    "def load_IMDB_dataset(dataset_name, return_dataframe = True):\n",
    "    # Проверяем, есть ли у нас уже скачанный датасет\n",
    "    if not dataset_name in os.listdir('datasets'):\n",
    "        # Загружаем датасет с сайта IMDB\n",
    "        print(f'Скачиваем `{dataset_name}`')\n",
    "        with urlopen(PATH_IMDB_DATASETS + dataset_name) as f_imdb_site:\n",
    "            with open('datasets/' + dataset_name, 'wb') as f_local:\n",
    "                f_local.write(f_imdb_site.read())\n",
    "    else:\n",
    "        print(f'Обнаружен датасет `{dataset_name}`')\n",
    "\n",
    "    # Вычислим и покажем размер файла с датасетом в байтах\n",
    "    print(f'Размер датасета `{dataset_name}` составляет {os.path.getsize(\"datasets/\" + dataset_name)} байт')\n",
    "\n",
    "    if return_dataframe:\n",
    "        # Загрузим датасет из скачанного файла. Разделитель \\t, неопределенные значения записаны как \\N, файл сжат gzip\n",
    "        # dtype=str нужен, чтобы быстрее загрузить датасет, иначе python анализирует каждую ячейку. Пусть грузит строки\n",
    "        return pd.read_csv(\"datasets/\" + dataset_name, sep='\\t', dtype=str, na_values= r'\\N', compression='gzip')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этот блок кода нужен при повторном запуске Jupiter-блокнота в ходе одного сеанса\n",
    "# Оказалось, что при повторной загрузке в память нужно удалять датафрейм явным способом при помощи del\n",
    "# Самый простой способ узнать, была ли переменная ранее определена, поискать ее в vars()\n",
    "if 'data_source' in vars():\n",
    "    del data_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загрузим информацию о фильмах\n",
    "data_source = load_IMDB_dataset(DATASET_MOVIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Из описания датасета мы знаем, что titleType содержит тип записи. Посмотрим внимательнее на содержимое этого поля\n",
    "data_source.titleType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Можно изучить оригинальный датасет\n",
    "data_source.info(null_counts=True) # без counts=True не будет выведена информация о Non-Null\n",
    "# data_source.describe(include='all') # можно было использовать include='object', но так надежнее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим на запись о фильмах с пустыми полями startYear, runtimeMinutes или genres\n",
    "data_source[(data_source.titleType == 'movie') \n",
    "    &(   data_source.startYear.isna()\n",
    "        |data_source.runtimeMinutes.isna()\n",
    "        |data_source.genres.isna()\n",
    "    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скорее всего, речь идет об утерянных фильмах или невышедших, но аносированных премьерах\n",
    "# Не будем брать их в нашу выборку "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сформируем нужную нам выборку фильмов (titleType == 'movie').\n",
    "# Если для фильма неизвестен год выпуска, его длительность или жанр, то их мы не берем. Зачем нам такое?\n",
    "# в последних строках выбираем столбцы, которые хотим оставить и переименовываем их\n",
    "data_movies = data_source[(data_source.titleType == 'movie')\n",
    "    # Чтобы оставить в датасете NaN (например, в учебных челях), достаточно удалить или закомментировать фильтпры\n",
    "    &data_source.startYear.notna()\n",
    "    &data_source.runtimeMinutes.notna()\n",
    "    &data_source.genres.notna()\n",
    "    ] \\\n",
    "    [['tconst', 'originalTitle', 'startYear', 'runtimeMinutes', 'genres']] \\\n",
    "    .set_axis(['imdb_id', 'original_title', 'release_year', 'runtime', 'genres'], axis = 'columns')\n",
    "\n",
    "# заменим заяпяые на `|` в списке жанров\n",
    "data_movies.genres = data_movies.genres.str.replace(',','|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загрузим информацию об оценках\n",
    "data_source = load_IMDB_dataset(DATASET_RATINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Изучим датасет оценок\n",
    "data_source.info(null_counts=True)\n",
    "data_source.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Оставим информацию о рейтингах фильмов из нашей выборки\n",
    "# И переименуем столбец, содержащий imdb_id\n",
    "data_ratings = data_source[(data_source.tconst.isin(data_movies.imdb_id))] \\\n",
    "    .rename(columns={'tconst': 'imdb_id'})\n",
    "\n",
    "# Сразу надо освободить память от неиспользуемых объектов\n",
    "if 'data_source' in vars():\n",
    "    del data_source\n",
    "\n",
    "# Посмотрим на датасет\n",
    "data_ratings.info()\n",
    "data_ratings.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сразу надо освободить память от неиспользуемых объектов\n",
    "if 'data_source' in vars():\n",
    "    del data_source\n",
    "\n",
    "# Посмотрим на датасет\n",
    "data_movies.info()\n",
    "data_movies.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Попродуем загрузить датасет с информацией о съемочных группах с опцией LOW_MEMORY_OPTION = False\n",
    "LOW_MEMORY_OPTION = True\n",
    "\n",
    "if not LOW_MEMORY_OPTION:\n",
    "    # Загрузим информацию о съемочных группах из полного датасета\n",
    "    data_source = load_IMDB_dataset(DATASET_CASTS)\n",
    "\n",
    "# Если датасет не загружается из-за нехватки памяти, то установим LOW_MEMORY_OPTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if LOW_MEMORY_OPTION:\n",
    "    # Можно столкнуться с проблемами при загрузке полного датасета из-за нехватки памяти\n",
    "    # В этом случае надо провести предварительную обработку обработку исходных данных\n",
    "\n",
    "    # Освободим память\n",
    "    if 'data_source' in vars():\n",
    "        del data_source\n",
    "\n",
    "    # Загрузим датасет без считывания датафрейма\n",
    "    load_IMDB_dataset(DATASET_CASTS, return_dataframe = False)\n",
    "    \n",
    "    # Построчно прочитаем файл и сохраним его отфильтрованный вариант\n",
    "    # Так как файл большой и фильтруется относительно долго (несколько минут), то добавим интерактивности\n",
    "    line_counts = 0 # сколько записей обработано\n",
    "    new_line_counts = 0 # сколько записей мы записали в новый датасет\n",
    "\n",
    "    filter_imdb_id = set(data_movies.imdb_id.values) # если не преобразовать в сет, проверка вхождения очень медленная\n",
    "    filter_category = set(['actor', 'actress', 'director']) # переход к сету при проверке категорий ускорил все в 4 раза\n",
    "\n",
    "    # Так как датасет заархивирован, читаем прямо из архива. Распакованный файл весил бы около 2 гб\n",
    "    with gzip.open('datasets/' + DATASET_CASTS, 'rt', encoding='utf-8') as f_original, \\\n",
    "        gzip.open('datasets/' + 'filtered_' + DATASET_CASTS, 'wt', encoding='utf-8') as f_filtered:\n",
    "        for line_tsv in f_original:\n",
    "            line_counts += 1\n",
    "            tconst, ordering, nconst, category, job, characters = line_tsv.split('\\t')\n",
    "            if line_counts == 1:\n",
    "                f_filtered.write(line_tsv) # записываем заголовок\n",
    "            elif (category in filter_category) and (tconst in filter_imdb_id):\n",
    "                f_filtered.write(line_tsv)\n",
    "                new_line_counts += 1\n",
    "            if line_counts % 77711 == 0: # любое число-интервал для обновления счетчика, взяли красивое простое число\n",
    "                print(f'Обработано {line_counts} строк. Записано {new_line_counts} строк.     ', end='\\r')\n",
    "        else:\n",
    "            print(f'Обработано {line_counts} строк. Записано {new_line_counts} строк.     ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if LOW_MEMORY_OPTION:\n",
    "    # Загрузим информацию об актерах из отфильтрованнойго датасета\n",
    "    data_source = load_IMDB_dataset('filtered_' + DATASET_CASTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Изучим датасет по съемочным группам\n",
    "data_source.info(null_counts=True)\n",
    "data_source.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Интересно посмотреть, какие есть категории. В полном датасете, с опцией LOW_MEMORY_OPTION = False их больше\n",
    "data_source[data_source.tconst.isin(data_movies.imdb_id)].category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Оставим информацию только об актерах и режиссерах только по фильмам из нашей выборки\n",
    "# И переименуем столбец, содержащий imdb_id\n",
    "data_casts = data_source[(data_source.tconst.isin(data_movies.imdb_id))\n",
    "    &data_source.category.isin(['actor', 'actress', 'director'])] \\\n",
    "    .rename(columns={'tconst': 'imdb_id', 'nconst': 'people_id'}) # удобная функция для переименования пары колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Освободим память\n",
    "if 'data_source' in vars():\n",
    "    del data_source\n",
    "\n",
    "# Посмотрим на датасет\n",
    "data_casts.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переименуем 'actor' и 'actress' в 'cast'\n",
    "data_casts.category[(data_casts.category == 'actor') | (data_casts.category == 'actress')] = 'cast'\n",
    "data_casts.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Интересно, что в job?\n",
    "data_casts.groupby(by = 'category').job.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Загрузим информацию о людях\n",
    "data_source = load_IMDB_dataset(DATASET_PEOPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Изучим\n",
    "data_source.info(null_counts=True)\n",
    "# data_source.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Оставим информацию о людях только из нашей выборки\n",
    "data_peoples = data_source[['nconst', 'primaryName', 'birthYear']] \\\n",
    "    [(data_source.nconst.isin(data_casts.people_id))] \\\n",
    "    .rename(columns={'nconst': 'people_id'}) # и переименуем имя колонки с id\n",
    "\n",
    "# Сразу надо освободить память от неиспользуемых объектов\n",
    "# if 'data_source' in vars():\n",
    "#     del data_source\n",
    "\n",
    "# Посмотрим на датасет\n",
    "data_peoples.info()\n",
    "data_peoples.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Все доступные датасеты загружены\n",
    "# Вспомним, где у нас что лежит и сформируем итоговый датасет\n",
    "list(data_movies), list(data_ratings), list(data_casts), list(data_peoples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Для сворачивания в одну ячейку сведений о режисерах и актерах подготовим специальный датафрейм\n",
    "df_casts_list = data_casts[['imdb_id', 'people_id', 'category']]\\\n",
    "    .merge(right = data_peoples, on ='people_id') \\\n",
    "    .assign(ordering = data_casts.ordering.astype(int)) \\\n",
    "    .sort_values(by=['imdb_id', 'category', 'ordering']) \\\n",
    "    .set_index('imdb_id') \\\n",
    "    [['category', 'primaryName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_casts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Заполним словари режиссеров и актеров, в качестве ключа используем imdb_id\n",
    "cast_dict={}\n",
    "for imdb_id, primaryName in df_casts_list[df_casts_list.category == 'cast'].primaryName.iteritems():\n",
    "    cast_dict.setdefault(imdb_id, '')\n",
    "    cast_dict[imdb_id] += '|' + primaryName\n",
    "\n",
    "director_dict={}\n",
    "for imdb_id, primaryName in df_casts_list[df_casts_list.category == 'director'].primaryName.iteritems():\n",
    "    director_dict.setdefault(imdb_id, '')\n",
    "    director_dict[imdb_id] += '|' + primaryName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Сформируем таблицу с данными в том же формате, что и у учебной базы\n",
    "# Информации о бюджете, кассовых сборах, студих, дате релиза, описании и ключевых славах\n",
    "# в открытом датасете IMDb, к сожалению, нет\n",
    "data = data_movies \\\n",
    "    .merge(right = data_ratings.rename(columns={'averageRating': 'vote_average', 'numVotes': 'num_votes'}),\n",
    "#            how='left', # если хотим получить выборку с фильмами без рейтинга, раскомментируем строку\n",
    "           on='imdb_id') \\\n",
    "    .merge(right = pd.DataFrame(pd.Series(cast_dict).str[1:], columns=['cast']), \n",
    "#            how='left', # если хотим получить выборку с фильмами без актеров, раскомментируем строку\n",
    "           left_on='imdb_id', right_index = True) \\\n",
    "    .merge(right = pd.DataFrame(pd.Series(director_dict).str[1:], columns=['director']), \n",
    "#            how='left', # если хотим получить выборку с фильмами без режиссеров, раскомментируем строку\n",
    "           left_on='imdb_id', right_index = True) \\\n",
    "    .reset_index(drop = True) \\\n",
    "    [['imdb_id', 'original_title', 'cast', 'director', 'runtime', 'genres', 'vote_average', 'num_votes', 'release_year']]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем итоговый файл, который возможно будет использовать в учебном проекте\n",
    "# Можно в архиированном виде, pd.read_csv() по расширению поймет, что надо разархивировать данные при чтении из файла\n",
    "data.to_csv('movie_imdb_dataset.csv.gz', index=False, compression='gzip')\n",
    "\n",
    "# Этот файл можно скоппировать в каталог с проектом «Кто хочет стать миллионером кинопроката?»\n",
    "# и прорешать его не на 1889, а на 183835 фильмах\n",
    "# data = pd.read_csv('movie_imdb_dataset.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# В качестве бонуса для тех, кто досмотрел до конца - код функции вывода постера по imdb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.core.display import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Указанный ниже SECRET_TMDB_API_KEY может перестать работать, тогда надо будет получить новый\n",
    "# Инструкция здесь - https://www.themoviedb.org/documentation/api/\n",
    "SECRET_TMDB_API_KEY = '74c77374f25ceb2688ab912ddab305f7'\n",
    "\n",
    "def imdb_poster(imdb_id):\n",
    "    url_movie_info = \"https://api.themoviedb.org/3/find/\" + imdb_id \\\n",
    "        + \"?api_key=\" + SECRET_TMDB_API_KEY + \"&external_source=imdb_id\"\n",
    "    try:\n",
    "        url_pict = 'http://image.tmdb.org/t/p/w300' \\\n",
    "            + re.search(r'poster_path\":\"([^\"]*)', urlopen(url_movie_info).read().decode()).group(1)\n",
    "        return Image(url_pict)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем информацию и постер одного из фильмов\n",
    "display(data[data.imdb_id=='tt1298650'])\n",
    "imdb_poster('tt1298650')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "developer_info": {
   "name": "nigani"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
